{
  "qualifiedName": "@deeppath-ai/mcp-crew-risk",
  "displayName": "mcp-crew-risk",
  "description": "This framework aims to provide crawler developers and operators with a comprehensive automated compliance detection toolset to evaluate the crawler-friendliness and potential risks of target websites. It covers three major dimensions: legal, social ethics, and technical aspects. Through multi-level risk warnings and specific recommendations, it helps plan crawler strategies reasonably to avoid legal disputes and negative social impacts while improving technical stability and efficiency.",
  "iconUrl": "https://spjawbfpwezjfmicopsl.supabase.co/storage/v1/object/public/server-icons/99685d4f-6add-46c9-af85-fe5760c793cc.png",
  "remote": true,
  "deploymentUrl": "https://server.smithery.ai/@deeppath-ai/mcp-crew-risk",
  "connections": [
    {
      "type": "http",
      "deploymentUrl": "https://server.smithery.ai/@deeppath-ai/mcp-crew-risk/mcp",
      "configSchema": {
        "type": "object",
        "title": "MCP Session Configuration",
        "properties": {
          "server": {
            "type": "object",
            "properties": {
              "host": {
                "type": "string",
                "description": "The host to bind the server to. Default is localhost. Use 0.0.0.0 to bind to all interfaces"
              },
              "port": {
                "type": "number",
                "description": "The port to listen on for SSE or MCP transport"
              }
            },
            "additionalProperties": false
          }
        },
        "description": "Schema for the /mcp endpoint configuration",
        "x-mcp-version": "1.0",
        "x-query-style": "dot+bracket",
        "additionalProperties": false
      }
    }
  ],
  "security": null,
  "tools": [
    {
      "name": "assess-crew-risk",
      "description": "This system evaluates the compliance and potential risks associated with web crawling activities. It is designed to assist developers, legal teams, and data professionals in ensuring that their crawlers operate within acceptable technical, legal, and ethical boundaries.",
      "inputSchema": {
        "type": "object",
        "$schema": "http://json-schema.org/draft-07/schema#",
        "required": [
          "url"
        ],
        "properties": {
          "url": {
            "type": "string",
            "description": "Web page URL, for example: https://www.xxx.com"
          }
        },
        "additionalProperties": false
      }
    }
  ],
  "_sync": {
    "fetched_at": "2026-01-04T13:50:24.481769+00:00",
    "source": "smithery"
  }
}